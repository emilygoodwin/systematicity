# Generating the Dataset 
## Basic steps
First, `python genblocks.py` (it may take a few minutes) 
This will create a directory & put the dataset in it (step_n/all_data.csv where n is your step #) 
`all_data.csv` contains all sentences in train, test, and dev

## all_data.csv 
Entries in `all_data.csv` look like this: 
`S1, S2, Correct_label, ID#, TestBoolean, TypeCode, VerbBlock, NounBlock, stepAdded, neighbours`
- **Sentence 1, Sentence 2**: Sentences, parsed, labeled constituents
- **Correct label**: Either = (equal); < (forward entail); > (reverse entail); | (alternation); v (cover); ^ (negation); # (else) 
- **ID#**: unique identifier for each sentence pair
- **TestBoolean**: 0 if Train, 1 if Test
- **TypeCode**:a three-letter code; describes which test/train condition this item was sampled from (see below) 
- **VerbBlock, NounBlock**: What hierarchy Nouns and Verbs were sampled from
- **StepAdded**: For generating multiple sets with increasing train size; the results reported in the paper are from two training conditions, the smaller of which could be generated with config_step0.yml and the large condition can be generated with config_step2.yml. 
- **neighbours**: list of IDs for items that are one edit distance away 

## The language 
### Nouns and verbs 
All nouns and verbs have the form XY.Z where: \
X is a letter representing the part of speech: N for noun or V for verb \
Y is a number, representing the hierarchy (between 0 and 99) \
Z is a number, representing the position in the hierarchy (between 0 and 5) \
- the number of hierarchies & words per hierarchy can be set in `config.yml`
- Function words (relative clauses, quantifiers, modifiers) are normal English words to make things easier to read.

### Some vocabulary:
**Hierarchies** of nouns and verbs (ex: pig < mammal < animal) describe a set of vocabulary items that are in an entailment hierarchy. Two nouns from within the same hierarchy will always be in an entailment/reverse entailment relationship; two nouns from different hierarchies will be unrelated (such sentence pairs are not generated by this code) \
**Block** is the set of all sentence pairs which can be generated from a single noun & single verb hierarchy. Function words (everything not a noun or verb) are shared across all blocks. \
A **Core set** is a set of sentence pairs, sampled from a single block, such that every noun, noun, verb, verb combination of the two hierarchies is represented once. 

## blocks.csv 
Running `gen_blocks.py` first creates a matrix with all possible combinations of noun & verb hierarchies, representing every possible block of sentences that we can sample from. This is saved to `blocks.csv`, and is used to keep track of which blocks are sampled from for test or train (i.e, which noun and verb hierarchies appear in test and train). \
Most entries will be (0,0,) meaning this combination of nouns and verbs was not sampled for either train or test. Entries populated with tuples describe a the training and testing condition (traincode, testcode), and signify that one coreset from this block will be included in train, and one in test. \
For example, the first line of blocks.csv (if you have not touched `config.yml`) should look like this:\
`['nin', 'TIR'],[0, 0],[0, 0],['ncr', 'TCR'],[0, 0], [0,0] [0,0]`\
The first entry in the matrix, (‘nin’, ‘TIR’), means we will sample sentences with nouns from nounhierarchy0  and verbs from  verbhierarchy0.
The fourth entry (‘ncr’, ‘TCR’), means we will sample sentences with nouns from nounhierarchy3 and verbs from verbhierarchy3.
If you run `tail blocks.csv` you will see that some entries are `[0, TIW]`, meaning we sample from this block in test, and not in train. These blocks are the jabberwocky items discussed in the paper. 

#### understanding train/test conditions: 
The entries are pairs of 3-letter codes, describing which train or test condition the vocabulary from this cell should be treated as. \
Deciphering the train condition:
- nin: sampled for train, nouns & verbs are ‘intrablock’ 
- ncr: sampled for train, nouns & verbs are ‘crossblock’

‘intrablocks’ sample nouns and verbs from the same hierarchy; ‘Cross blocks’ mix hierarchies, (for example nouns from 4 but verbs from 12). This is only relevant if you want to try testing novel combinations of familiar nouns and verbs; when testing jabberwocky items this is not a relevant distinction.

Deciphering the test condition: 
- First letter: t (test) 
- Second letter: i (‘intra’) or c (‘cross’ block) 
- Third letter: r (this cell will be sampled from for train) 
  - f (this cell will not be sampled from for train, the mirrored cell (across diagonal) will be, the two intra cells for nouns & verbs will be)
  - n (this cell will not be sampled from for train, the mirrored cell (across diagonal) will not be, the two intra cells for nouns & verbs will be)
  - W (this cell will not be sampled from for train, the mirrored cell (across diagonal) will not be, the two intra cells for nouns & verbs will not be) These are the **jabberwocky items**. The W stands for 'wug', as in 'wug test', although since these experiments are more accurately described as jabberwocky items it should probably be J. 

#### replicating jabberwocky tests
The train/test codes are used in the `all_data.csv` file, to identify which test condition an item is. If you are trying to replicate the jabberwocky testing, you want a matrix that assigns part of the vocabulary to train and part of it to test. You do not care about which noun hierarchies are combined with which verb hierarchies. The only codes that matter for you are:
Use the config_step0.yml file to generate a dataset corresponding to the 'small' training condition from the paper. 
config_step2.yml corresponds to the 'large' training condition in the paper. 


1. jabberwocky test items `tiw` (neither noun nor verb hierarchy is shown during train) 
2. neighbouring test items `nbr` (items included in test because they are one edit-distance away from a `tiw` test item. These items represent the transformations tested in the paper: insertion, deletion or substitution of a known word, transposition of the sentences, etc)
3. control test items `tir` (the noun and verb hierarchy were both shown during train). 
4. training items `nin` or `ncr` 
5. dev set items `dev`

